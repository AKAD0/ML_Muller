{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6. NLP\n",
    "# Part 1. Basis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Data preparation (very slow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "reviews_train = load_files(\"imdb/aclimdb/train\")\n",
    "reviews_test = load_files(\"imdb/aclimdb/train\")\n",
    "\n",
    "text_train, y_train = reviews_train.data, reviews_train.target\n",
    "text_train = [doc.replace(b\"<br />\", b\" \") for doc in text_train]\n",
    "\n",
    "text_test, y_test = reviews_test.data, reviews_test.target\n",
    "text_test = [doc.replace(b\"<br />\", b\" \") for doc in text_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 13\n",
      "Vocabulary content: \n",
      "{'the': 9, 'fool': 3, 'doth': 2, 'think': 10, 'he': 4, 'is': 6, 'wise': 12, 'but': 1, 'man': 8, 'knows': 7, 'himself': 5, 'to': 11, 'be': 0}\n",
      "Sparse matrix content: \n",
      "[[0 0 1 1 1 0 1 0 0 1 1 0 1]\n",
      " [1 1 0 1 0 1 0 1 1 1 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "bards_words = [\"The fool doth think he is wise,\", \"but the wise man knows himself to be a fool\"]\n",
    "vect = CountVectorizer().fit(bards_words)\n",
    "bag_of_words = vect.transform(bards_words)\n",
    "\n",
    "print(\"Vocabulary size: {}\".format( len( vect.vocabulary_)))\n",
    "print(\"Vocabulary content: \\n{}\".format( vect.vocabulary_))\n",
    "print(\"Sparse matrix content: \\n{}\".format( bag_of_words.toarray()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ Sparse matrix shows how many tockens there is in document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Movie review tonality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BoW model init and build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:\n",
      "<75000x124255 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 10315542 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer().fit(text_train)\n",
    "X_train = vect.transform(text_train)\n",
    "print(\"X_train:\\n{}\".format( repr( X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check vocabulary (detailed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 124255\n",
      "\n",
      "First 5 features: ['00', '000', '0000', '0000000000000000000000000000000001', '0000000000001']\n",
      "\n",
      "Middle 5 features: ['cheapest', 'cheapie', 'cheapies', 'cheapjack', 'cheaply']\n",
      "\n",
      "Every 10000th feature: ['00', 'banqui√®re', 'chcialbym', 'devagan', 'fetiches', 'heathen', 'kerchner', 'meistersinger', 'overwhelmingly', 'recreating', 'silveira', 'themself', 'weidler']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_names = vect.get_feature_names()\n",
    "\n",
    "print(\"Number of features: {}\\n\".format( len( feature_names)))\n",
    "print(\"First 5 features: {}\\n\".format( feature_names[:5]))\n",
    "print(\"Middle 5 features: {}\\n\".format(feature_names[20015:20020]))\n",
    "print(\"Every 10000th feature: {}\\n\".format(feature_names[::10000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logreg model init and build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) CV training model. EXTREMELY LONG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "scores = cross_val_score(LogisticRegression( max_iter=99999999), X_train, y_train, cv=5)\n",
    "print(\"Mean cv quality: {}\".format( np.mean( scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ Accuracy=0.88. Probably could be better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) GridSearching best 'C' param. EXTREMELY LONG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C':[0.001,0.01,0.1,1,10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(LogisticRegression(), param_grid, cv=5).fir(X_train, y_train)\n",
    "print('Best cv value: {:.2f}'.format(grid.best_score_))\n",
    "print('best params: {}', grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ Thus best 'C'=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vect.transform(text_test)\n",
    "print('Quality: {:2.f}'.format(grid.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ Accuracy=0.88. Same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Reducing number of worthless tokens and applying to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train c min_df: <75000x44532 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 10191240 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer( min_df=5).fit(text_train)\n",
    "X_train = vect.transform(text_train)\n",
    "print('X_train c min_df: {}'.format( repr( X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ Feature number decreased in 3 times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check vocabulary (detailed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 44532\n",
      "\n",
      "First 5 features: ['00', '000', '001', '007', '00am']\n",
      "\n",
      "Middle 5 features: ['inevitable', 'inevitably', 'inexcusable', 'inexcusably', 'inexhaustible']\n",
      "\n",
      "Every 10000th feature: ['00', 'deck', 'ineffectually', 'policies', 'tinkles']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_names = vect.get_feature_names()\n",
    "\n",
    "print(\"Number of features: {}\\n\".format( len( feature_names)))\n",
    "print(\"First 5 features: {}\\n\".format( feature_names[:5]))\n",
    "print(\"Middle 5 features: {}\\n\".format(feature_names[20015:20020]))\n",
    "print(\"Every 10000th feature: {}\\n\".format(feature_names[::10000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV( LogisticRegression(), param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "print('Best CV accuracy: {}'.format( grid.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ Accuracy hasn't increased. Feature processing may increase algorithm's speed and result's interpretability though."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
