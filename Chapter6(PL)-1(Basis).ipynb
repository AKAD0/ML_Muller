{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "comparative-machinery",
   "metadata": {},
   "source": [
    "# Chapter 6. Pipelines.\n",
    "# Part 1. Basis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defensive-panic",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "1) Data Scaling should be applied only to the training folds, thus cross-validation should be done BEFORE scaling in terms of using pipeline.\n",
    "\n",
    "2) There could be any number of stages in pipeline with the only requirement to keep all stages (except last one) to have method 'transform' in a such way that new transformed data could be used for next stage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tender-fault",
   "metadata": {},
   "source": [
    "Setting up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "blond-cathedral",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.972027972027972\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#-----dataset preparing\n",
    "cancer = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, random_state=0)\n",
    "#scaling\n",
    "scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "#-----model initialization and building\n",
    "svm = SVC().fit(X_train_scaled, y_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print('Test accuracy: {}'.format(svm.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weird-stationery",
   "metadata": {},
   "source": [
    "## - Building Pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "postal-confusion",
   "metadata": {},
   "source": [
    "Corteges made of preferred name and used model are representing stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "minimal-sucking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.972027972027972\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#initialization and building pipeline model:\n",
    "pipe = Pipeline([('scaler', MinMaxScaler()), ('svm', SVC())])\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "#accuracy:\n",
    "print('Test accuracy: {}'.format(pipe.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revised-literature",
   "metadata": {},
   "source": [
    "There's also a handy way to build pipeline via 'make_pipeline'. It's the same thing but the stage's name is assigned automatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dying-token",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipelines stages:\n",
      "[('minmaxscaler', MinMaxScaler()), ('svc', SVC(C=100))]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "#standard syntax:\n",
    "pipe_long = ([('scaler', MinMaxScaler()), ('svm', SVC(C=100))])\n",
    "#'make_pipeline' syntax:\n",
    "pipe_short = make_pipeline(MinMaxScaler(), SVC(C=100))\n",
    "\n",
    "#assigned stage names within corteges:\n",
    "print('Pipelines stages:\\n{}'.format(pipe_short.steps))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "close-origin",
   "metadata": {},
   "source": [
    "## - Building Pipelines (GridSearchCV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objective-ideal",
   "metadata": {},
   "source": [
    "Using GridSearchCV with pipelines is the same as usual (put the model inside GridSearchCV) but the grid itself should be assigned via specific syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "desperate-cabinet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation accuracy: 0.9812311901504789\n",
      "Test accuracy: 0.972027972027972\n",
      "Best params: {'svm__C': 1, 'svm__gamma': 1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'svm__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "              'svm__gamma': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print('Best cross-validation accuracy: {}'.format(grid.best_score_))\n",
    "print('Test accuracy: {}'.format(grid.score(X_test, y_test)))\n",
    "print('Best params: {}'.format(grid.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metropolitan-modeling",
   "metadata": {},
   "source": [
    "## - Accessing stage's atributes\n",
    "To see stage's model atributes it should be used 'named_steps' which is a dictionary of names attached to models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "virgin-durham",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps: {'standardscaler-1': StandardScaler(), 'pca': PCA(n_components=2), 'standardscaler-2': StandardScaler()}\n",
      "\n",
      "PCA components shape: (2, 30)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(), PCA(n_components=2), StandardScaler())\n",
    "\n",
    "pipe.fit(cancer.data)\n",
    "components = pipe.named_steps['pca'].components_\n",
    "\n",
    "print('Steps: {}\\n'.format(pipe.named_steps))\n",
    "print('PCA components shape: {}'.format(components.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "toxic-boating",
   "metadata": {},
   "source": [
    "## - Accessing stage's atributes (GridSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ignored-feature",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model:\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('logisticregression', LogisticRegression(C=1))])\n",
      "\n",
      "Logreg stage:\n",
      "LogisticRegression(C=1)\n",
      "\n",
      "Logreg coefs:\n",
      "[[-0.43570655 -0.34266946 -0.40809443 -0.5344574  -0.14971847  0.61034122\n",
      "  -0.72634347 -0.78538827  0.03886087  0.27497198 -1.29780109  0.04926005\n",
      "  -0.67336941 -0.93447426 -0.13939555  0.45032641 -0.13009864 -0.10144273\n",
      "   0.43432027  0.71596578 -1.09068862 -1.09463976 -0.85183755 -1.06406198\n",
      "  -0.74316099  0.07252425 -0.82323903 -0.65321239 -0.64379499 -0.42026013]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akado/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/akado/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/akado/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/akado/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/akado/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    cancer.data, cancer.target, random_state=4)\n",
    "\n",
    "param_grid = {'logisticregression__C': [0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5).fit(X_train, y_train)\n",
    "\n",
    "print('Best model:\\n{}\\n'.format(grid.best_estimator_))\n",
    "print('Logreg stage:\\n{}\\n'.format(grid.best_estimator_.named_steps['logisticregression']))\n",
    "print('Logreg coefs:\\n{}\\n'.format(grid.best_estimator_.named_steps['logisticregression'].coef_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
